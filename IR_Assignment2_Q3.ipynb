{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR_Assignment2_Q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IR Assignment 2\n",
        "#### Samad Shahid   2019446\n",
        "#### Shashwat Goyal 2019447"
      ],
      "metadata": {
        "id": "6JBYScGYzqaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xPFL0nHwdP3l"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "from operator import countOf\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lhz_HIJddgq",
        "outputId": "73c550b4-6d2b-4aea-807b-7b36a38f09ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '20_newsgroups.zip' # Extracts Zip file\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "print('Extraction Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# folders=os.listdir(r'C:\\Users\\shash\\Desktop\\ira1')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords') # downloading packages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwY57iFnOEKM",
        "outputId": "8dccc9e4-c776-4d77-c219-f2a138020b7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ters(inp):\n",
        "    temp=(c for c in inp if not c.isdigit() and c.isalnum() and c not in string.punctuation) # removes digits and punctuations\n",
        "    one=1\n",
        "    zero=0\n",
        "    for i in range(1,2):\n",
        "      one=one+zero\n",
        "    temp1=''\n",
        "    return temp1.join(temp)"
      ],
      "metadata": {
        "id": "rsEJttZMIL84"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pro(inp):\n",
        "    one=1\n",
        "    zero=0\n",
        "    stop=set(stopwords.words('english')) # makes a set of stopwords\n",
        "    wordt = word_tokenize(inp.lower())  # lowers the words\n",
        "    # wordt = list(dict.fromkeys(wordt))  # removes duplicates \n",
        "    for i in range(1,2):\n",
        "      one=one+zero\n",
        "    valid=[k for k in wordt if k not in stop]  #if the word is valid\n",
        "    valid=[ters(k) for k in valid]\n",
        "    for i in range(1,2):\n",
        "      one=one+zero\n",
        "    valid=[k for k in valid if len(k) > 1*one] # checking to see if length is greater than 1\n",
        "    return valid"
      ],
      "metadata": {
        "id": "0bjgn_XJIJdo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readf(filep):\n",
        "    try:\n",
        "        with open(filep ,'r',encoding = \"utf-8\", errors = 'replace') as ff:\n",
        "            corpus = ff.read().replace('\\n', ' ')\n",
        "            one=1\n",
        "            zero=0\n",
        "            corpus = pro(corpus)\n",
        "            for i in range(1,2):\n",
        "              one=one+zero\n",
        "            return corpus\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "ElrKSF43IGvS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_comp=[]\n",
        "words_med=[]\n",
        "words_politics=[]\n",
        "words_hockey=[]\n",
        "words_space=[]\n",
        "for folder in os.listdir('20_newsgroups/comp.graphics'):\n",
        "  # comp_g=os.path.join(path,'comp.graphics')\n",
        "  path=\"20_newsgroups/comp.graphics\"\n",
        "  words_comp.append((readf(os.path.join(path,folder))))\n"
      ],
      "metadata": {
        "id": "xtvS8IlBG6kp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words_comp))"
      ],
      "metadata": {
        "id": "5zisSHvWTtze",
        "outputId": "87bfda66-f4e3-418c-d210-55ebe2097ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir('20_newsgroups/sci.med'):\n",
        "  # comp_g=os.path.join(path,'comp.graphics')\n",
        "  path=\"20_newsgroups/sci.med\"\n",
        "  words_med=(readf(os.path.join(path,folder)))\n",
        "# print(words_med[0])"
      ],
      "metadata": {
        "id": "gC3N5kwoIZYE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir('20_newsgroups/talk.politics.misc'):\n",
        "  # comp_g=os.path.join(path,'comp.graphics')\n",
        "  path=\"20_newsgroups/talk.politics.misc\"\n",
        "  words_politics=(readf(os.path.join(path,folder)))\n",
        "# print(type(words_politics))"
      ],
      "metadata": {
        "id": "Cnp652ENIlpk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir('20_newsgroups/rec.sport.hockey'):\n",
        "  # comp_g=os.path.join(path,'comp.graphics')\n",
        "  path=\"20_newsgroups/rec.sport.hockey\"\n",
        "  words_hockey=(readf(os.path.join(path,folder)))\n",
        "# print(type(words_hockey))"
      ],
      "metadata": {
        "id": "uxpdbcm7IscV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir('20_newsgroups/sci.space'):\n",
        "  # comp_g=os.path.join(path,'comp.graphics')\n",
        "  path=\"20_newsgroups/sci.space\"\n",
        "  words_space=(readf(os.path.join(path,folder)))\n",
        "# print(type(words_space))"
      ],
      "metadata": {
        "id": "Z46OAPQyO6aG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(words_comp)\n",
        "random.shuffle(words_politics)\n",
        "random.shuffle(words_med)\n",
        "random.shuffle(words_space)\n",
        "random.shuffle(words_hockey)"
      ],
      "metadata": {
        "id": "ptOUrqcvUr8J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into 80:20 train-test data\n",
        "\n",
        "train_comp = words_comp[:math.floor(len(words_comp)*0.8)]\n",
        "test_comp = words_comp[math.floor(len(words_comp)*0.8):]\n",
        "\n",
        "train_politics = words_politics[:math.floor(len(words_politics)*0.8)]\n",
        "test_politics = words_politics[math.floor(len(words_politics)*0.8):]\n",
        "\n",
        "train_med = words_med[:math.floor(len(words_med)*0.8)]\n",
        "test_med = words_med[math.floor(len(words_med)*0.8):]\n",
        "\n",
        "train_space = words_space[:math.floor(len(words_space)*0.8)]\n",
        "test_space = words_space[math.floor(len(words_space)*0.8):]\n",
        "\n",
        "train_hockey = words_hockey[:math.floor(len(words_hockey)*0.8)]\n",
        "test_hockey = words_hockey[math.floor(len(words_hockey)*0.8):]"
      ],
      "metadata": {
        "id": "SNAO28U7VKTA"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}